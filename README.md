# Linear Quadratic Regulator (LQR) and Reinforcement Learning

This repository contains two laboratory exercises focused on understanding optimal control theory, specifically the Linear Quadratic Regulator (LQR) and integrating the Proximal Policy Optimization (PPO) reinforcement learning algorithm. 

# 1. Linear Quadratic Regulator (LQR)
`TP1_Forearm_movements_and_LQR_model.ipynb`  introduces LQR by first performing basic manipulations of the data and then manually applying the LQR.
I The data used in this laboratory exercise come from a 2011 experiment where participants aimed towards a thin line using 5 different strategies ranging from fast to precise. The data can be found in the `Dataset` folder.

The lab has 4 parts: the first part is about basic manipulations of the data, and visualizing that data. The second and third part are ”courses”, and we will treat them together. The fourth part is about applying what you just learned in the course.

# 2. Reinforcement Learning through PPO

`TP2_Forearm_movements_and_PPO.ipynb` focuses on using the model-free reinforcement learning algorithm, PPO, to solve the optimization problem. The laboratory exercise uses the stable-baselines3 library, which contains an implementation of PPO. 

The results of the two laboratory exercises are represented and commented on within the notebook.

## Requirements 
Both laboratory exercises were developed in Google Colab and the required installations are detailed within each notebook.

## Usage
