# LQR - PPO
This repository contains two laboratory exercises focused on understanding optimal control theory, specifically the Linear Quadratic Regulator (LQR) and integrating the Proximal Policy Optimization (PPO) reinforcement learning algorithm. 

`TP1_Forearm_movements_and_LQR_model.ipynb`  introduces LQR by first performing basic manipulations of the data and then manually applying the LQR.
I The data used in this laboratory exercise come from a 2011 experiment where participants aimed towards a thin line using 5 different strategies ranging from fast to precise. The data can be found in the `Dataset` folder.

`TP2_Forearm_movements_and_PPO.ipynb` focuses on using the model-free reinforcement learning algorithm, PPO, to solve the optimization problem. The laboratory exercise uses the stable-baselines3 library, which contains an implementation of PPO. 

The results of the two laboratory exercises are represented and commented on within the notebook.

Both laboratory exercises were developed in Google Colab and the required installations are detailed within each notebook.
